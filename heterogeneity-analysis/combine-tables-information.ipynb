{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26138994",
   "metadata": {},
   "source": [
    "# Combining information from two tables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ffcad",
   "metadata": {},
   "source": [
    "This notebook contains code to compare and copy-paste information from one dataframe to another if the identity is the same.\n",
    "This notebook contains:\n",
    "<br> A) Combining information between tables of presynaptic partners\n",
    "<br> B) Combining information between tables of presynaptic partners and databse of postsynaptic partners\n",
    "<br> C) Combining information between tables of postsynaptic partners and databse of postsynaptic partners\n",
    "<br> D) Combining information between tables for neuron authorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33729fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fafbseg import flywire\n",
    "from caveclient import CAVEclient\n",
    "client = CAVEclient('flywire_fafb_production')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932839de",
   "metadata": {},
   "source": [
    "## A) Combining information between tables of presynaptic partners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860efd71",
   "metadata": {},
   "source": [
    "### Chossing files of interest and data to transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860220bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose path and file\n",
    "\n",
    "dataPath = r'Z:\\Further projects\\Heterogeneity across cell types\\data\\Excels\\drive-data-sets' # write your path\n",
    "fileName_list = ['Mi1_neurons_input_count_R_20240610.xlsx',\n",
    "                 'Mi4_neurons_input_count_R_20240610.xlsx']\n",
    "\n",
    "filePath_list = []\n",
    "for fileName in fileName_list:\n",
    "    filePath_list.append(os.path.join(dataPath,fileName))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose column information to compare and to transfer\n",
    "columns_to_compare = ['presynaptic_ID', 'postsynaptic_ID', 'seg_id']\n",
    "columns_to_transfer_based_on_pre = ['presynaptic_ID','postsynaptic_ID','symbol','guess','hemisphere','lab', 'author','name','twigs proofread (Y/N)', \n",
    "                                    'FlyWire proofread (Y/N)','identified_in', 'lab authorship (Y/N)', 'Extra notes as comments (initials)']\n",
    "columns_to_transfer_based_on_post = ['presynaptic_ID','postsynaptic_ID', 'optic_lobe_id','column_id','detached_lamina (Y/N)', 'healthy_L3 (Y/N)']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe861d",
   "metadata": {},
   "source": [
    "### Loading files as distict dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed19322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distinct dataframes will be stored in a dictionary\n",
    "\n",
    "data_frames = dict()\n",
    "\n",
    "for i in range(1, len(filePath_list)+1):\n",
    "    data_frames['df_%02d' % i] = pd.read_excel(filePath_list[i-1])\n",
    "    #Dropping the fisrt row ('asdf' was added as a walk-around to set that column values as type str)\n",
    "    if data_frames['df_%02d' % i][\"postsynaptic_ID\"][0] == 'asdf': \n",
    "        data_frames['df_%02d' % i] = data_frames['df_%02d' % i].iloc[1: , :]\n",
    "        data_frames['df_%02d' % i].reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df73ccd",
   "metadata": {},
   "source": [
    "### Updating column information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc59795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distinct columns to update and the updated versions of them will be stored dictionaries\n",
    "\n",
    "columns_to_update = dict()\n",
    "for df_name in data_frames.keys():\n",
    "    curr_df = data_frames[df_name]\n",
    "    for column_name in columns_to_compare:\n",
    "        columns_to_update[f'{df_name}_{column_name}'] = curr_df[column_name].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the 'INPUTS PROOFREAD' labelled row of the lists for a well-known marker id\n",
    "\n",
    "marker_id = '720575940628553731' # VM1 ORN\n",
    "marker_id_update_df = flywire.update_ids(marker_id, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "marker_id_updated = marker_id_update_df[\"new_id\"][0]\n",
    "for key,value in columns_to_update.items():\n",
    "    for i, id in enumerate(value):\n",
    "        if id == 'INPUTS PROOFREAD':\n",
    "            value[i] = marker_id_updated # Replacement by the marker\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35303e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the different columns. Information is stored in a dictionary\n",
    "updated_columns = dict()\n",
    "updated_columns_confidence = dict()\n",
    "for key, value in columns_to_update.items():\n",
    "    temp_segmentIDs_df = flywire.update_ids(value.tolist(), stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "    updated_value = temp_segmentIDs_df[\"new_id\"]\n",
    "    confidence_of_update = temp_segmentIDs_df[\"confidence\"]\n",
    "    updated_columns[key] = updated_value\n",
    "    updated_columns_confidence[key] = confidence_of_update\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79088b68",
   "metadata": {},
   "source": [
    "### Updating dataframe information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392254de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring the initial INPUTS PROOFREAD' marker\n",
    "for key, series in updated_columns.items():\n",
    "    updated_columns[key] = series.replace(to_replace = int(marker_id), value = 'INPUTS PROOFREAD')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c7ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the different dataframes inplace\n",
    "for df_name, df_values in data_frames.items():\n",
    "    for column_name in columns_to_compare:\n",
    "        data_frames[df_name][column_name] =  updated_columns[f'{df_name}_{column_name}']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c63c147",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9a214a2",
   "metadata": {},
   "source": [
    "### Transfering data from a source data frame into another\n",
    "#### Defining a function that performs the copy-paste operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d439069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataframe(source_df, target_df, reference_column1, reference_column2):\n",
    "    # Create a dictionary mapping from the reference columns to the source DataFrame\n",
    "    reference_columns = [reference_column1, reference_column2]\n",
    "    reference_dict = source_df.groupby(reference_columns).first().reset_index().to_dict(orient='records')\n",
    "    reference_dict = {(row[reference_column1], row[reference_column2]): row for row in reference_dict}\n",
    "\n",
    "    # Update the target DataFrame based on the reference columns\n",
    "    for i, row in target_df.iterrows():\n",
    "        ref1 = row[reference_column1]\n",
    "        ref2 = row[reference_column2]\n",
    "        if (ref1, ref2) in reference_dict:\n",
    "            source_row = reference_dict[(ref1, ref2)]\n",
    "            target_df.loc[i] = source_row\n",
    "\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72230d9",
   "metadata": {},
   "source": [
    "### Provide the user-chosen columns and reference column as inputs to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38044315",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_cols = columns_to_transfer_based_on_pre \n",
    "target_cols = columns_to_transfer_based_on_pre \n",
    "reference_column1 = 'presynaptic_ID'\n",
    "reference_column2 = 'postsynaptic_ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30e617",
   "metadata": {},
   "source": [
    "### Call the function with the source and target data frames and the provided inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4417a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = data_frames['df_01'][source_cols].copy()\n",
    "target_df = data_frames['df_02'][target_cols].copy()\n",
    "\n",
    "source_df = source_df.astype(str)\n",
    "target_df = target_df.astype(str)\n",
    "\n",
    "result_df = update_dataframe(source_df, target_df,reference_column1, reference_column2)\n",
    "presynaptic_result_df = result_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa63c52",
   "metadata": {},
   "source": [
    "### Repeating the same process but for postsynaptic_id-based information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_cols = columns_to_transfer_based_on_post \n",
    "target_cols = columns_to_transfer_based_on_post \n",
    "reference_column1 = 'presynaptic_ID'\n",
    "reference_column2 = 'postsynaptic_ID'\n",
    "\n",
    "source_df = data_frames['df_01'][source_cols].copy()\n",
    "target_df = data_frames['df_02'][target_cols].copy()\n",
    "\n",
    "source_df = source_df.astype(str)\n",
    "target_df = target_df.astype(str)\n",
    "\n",
    "result_df = update_dataframe(source_df, target_df,reference_column1, reference_column2)\n",
    "postsynaptic_result_df = result_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e2e0c",
   "metadata": {},
   "source": [
    "### Combining the data frames and saving the data in an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([presynaptic_result_df,postsynaptic_result_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05068261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving in a new file\n",
    "\n",
    "str_final_df = final_df.astype(str)\n",
    "\n",
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "date_str = x.strftime(\"%d\") + x.strftime(\"%b\") + x.strftime(\"%Y\")\n",
    "fileName_list[0]\n",
    "file_name = f'{fileName_list[1]}_UPDATED_from_{fileName_list[0]}_{date_str}.xlsx'\n",
    "savePath = os.path.join(dataPath, file_name)\n",
    "str_final_df.to_excel(savePath, sheet_name='Data frame update')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ce6cf",
   "metadata": {},
   "source": [
    "##  B) Combining information between tables of presynaptic partners and databse of postsynaptic partners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd20742",
   "metadata": {},
   "source": [
    "### Chossing files of interest and data to transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1db07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose path and file\n",
    "\n",
    "dataPath = r'C:\\Connectomics-Data\\FlyWire\\Excels\\drive-data-sets' # write your path\n",
    "fileName_list = [f'Mi1 proofreadings.xlsx',\n",
    "                 'Mi1_neurons_input_count_R_20240610.xlsx']\n",
    "\n",
    "filePath_list = []\n",
    "for fileName in fileName_list:\n",
    "    filePath_list.append(os.path.join(dataPath,fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose column information to compare and to transfer\n",
    "columns_to_compare = ['postsynaptic_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420947fd",
   "metadata": {},
   "source": [
    "### Loading the distinct data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9086f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distinct dataframes will be stored in a dictionary\n",
    "\n",
    "data_frames = dict()\n",
    "\n",
    "for i in range(1, len(filePath_list)+1):\n",
    "    data_frames['df_%02d' % i] = pd.read_excel(filePath_list[i-1])\n",
    "    #Dropping the fisrt row ('asdf' was added as a walk-around to set that column values as type str)\n",
    "    if data_frames['df_%02d' % i][\"seg_id\"][0] == 'asdf': \n",
    "        data_frames['df_%02d' % i] = data_frames['df_%02d' % i].iloc[1: , :]\n",
    "        data_frames['df_%02d' % i].reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming some columns different to match the two dataframes\n",
    "for df_name in data_frames.keys():\n",
    "    if 'postsynaptic_ID' not in data_frames[df_name].columns:\n",
    "        data_frames[df_name]['postsynaptic_ID'] = data_frames[df_name]['seg_id']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67da504",
   "metadata": {},
   "source": [
    "### Updating column information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb22bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distinct columns to update and the updated versions of them will be stored dictionaries\n",
    "columns_to_update = dict()\n",
    "for df_name in data_frames.keys():\n",
    "    curr_df = data_frames[df_name]\n",
    "    for column_name in columns_to_compare:\n",
    "        columns_to_update[f'{df_name}_{column_name}'] = curr_df[column_name].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the 'INPUTS PROOFREAD' or NaN labelled row of the lists for a well-known marker id\n",
    "\n",
    "marker_id = '720575940628553731' # VM1 ORN\n",
    "marker_id_update_df = flywire.update_ids(marker_id, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "marker_id_updated = marker_id_update_df[\"new_id\"][0]\n",
    "for key,value in columns_to_update.items():\n",
    "    for i, id in enumerate(value):\n",
    "        if id == 'INPUTS PROOFREAD':\n",
    "            value[i] = marker_id_updated # Replacement by the marker\n",
    "        elif id == float('nan'):\n",
    "            value[i] = marker_id_updated # Replacement by the marker\n",
    "        elif math.isnan(float(id)):\n",
    "            value[i] = marker_id_updated # Replacement by the marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13040f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the different columns. Information is stored in a dictionary\n",
    "updated_columns = dict()\n",
    "updated_columns_confidence = dict()\n",
    "for key, value in columns_to_update.items():\n",
    "    temp_segmentIDs_df = flywire.update_ids(value.tolist(), stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "    updated_value = temp_segmentIDs_df[\"new_id\"]\n",
    "    confidence_of_update = temp_segmentIDs_df[\"confidence\"]\n",
    "    updated_columns[key] = updated_value\n",
    "    updated_columns_confidence[key] = confidence_of_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f3124",
   "metadata": {},
   "source": [
    "### Updating dataframe information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964abf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring the initial INPUTS PROOFREAD' marker\n",
    "for key, series in updated_columns.items():\n",
    "    updated_columns[key] = series.replace(to_replace = int(marker_id), value = 'INPUTS PROOFREAD')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31baa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the different dataframes inplace\n",
    "for df_name, df_values in data_frames.items():\n",
    "    for column_name in columns_to_compare:\n",
    "        data_frames[df_name][f'Updated_{column_name}'] =  updated_columns[f'{df_name}_{column_name}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following ids have been updated\n",
    "query_name = 'df_01'\n",
    "diff_df = data_frames[query_name].astype(str).loc[data_frames[query_name].astype(str)['Updated_postsynaptic_ID'] != data_frames[query_name].astype(str)['postsynaptic_ID']]\n",
    "print('Previous:')\n",
    "print(diff_df['postsynaptic_ID'].unique())\n",
    "print('Updated:')\n",
    "print(diff_df['Updated_postsynaptic_ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fccbfc",
   "metadata": {},
   "source": [
    "### Transfering data from a source data frame into another\n",
    "#### Defining a function that performs the copy-paste operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa9efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataframe_single_column(source_df, target_df, reference_column):\n",
    "    # Create a dictionary mapping from the reference column to the source DataFrame\n",
    "    reference_dict = source_df.groupby(reference_column).first().reset_index().to_dict(orient='records')\n",
    "    reference_dict = {row[reference_column]: row for row in reference_dict}\n",
    "\n",
    "    # Update the target DataFrame based on the reference column\n",
    "    for i, row in target_df.iterrows():\n",
    "        ref = row[reference_column]\n",
    "        if ref in reference_dict:\n",
    "            source_row = reference_dict[ref]\n",
    "            target_df.loc[i] = source_row\n",
    "\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29943b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function inputs\n",
    "source_cols = ['optic_lobe_id', 'column_id','detached_lamina (Y/N)','healthy_L3 (Y/N)','postsynaptic_ID','Updated_postsynaptic_ID','dorso-ventral']\n",
    "target_cols = ['optic_lobe_id', 'column_id', 'detached_lamina (Y/N)','healthy_L3 (Y/N)','postsynaptic_ID','Updated_postsynaptic_ID','dorso-ventral']\n",
    "reference_column = 'postsynaptic_ID'\n",
    "\n",
    "# Selecting dataframes and resetting index\n",
    "source_df = data_frames['df_01'][source_cols].copy()\n",
    "source_df.reset_index(inplace = True, drop = True)\n",
    "target_df = data_frames['df_02'][target_cols].copy()\n",
    "target_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "source_df = source_df.astype(str)\n",
    "target_df = target_df.astype(str)\n",
    "\n",
    "# Running the function and compleating the dataset\n",
    "result_df = update_dataframe_single_column(source_df, target_df,reference_column)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dd6cd8",
   "metadata": {},
   "source": [
    "### Saving back to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf198c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating string for the date\n",
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "date_str = x.strftime(\"%d\") + x.strftime(\"%b\") + x.strftime(\"%Y\")\n",
    "\n",
    "# Writting in an existing excel file\n",
    "from openpyxl import load_workbook\n",
    "book = load_workbook(filePath_list[1])\n",
    "writer = pd.ExcelWriter(filePath_list[1], engine = 'openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "result_df = result_df.astype(str)\n",
    "result_df.to_excel(writer, sheet_name='Updated_table_'+date_str) #sorted_df\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60048cbf",
   "metadata": {},
   "source": [
    "## C) Combining information between tables of postsynaptic partners and database of postsynaptic partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7932a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose path and file\n",
    "\n",
    "dataPath = r'Z:\\Further projects\\Heterogeneity across cell types\\data\\Excels\\drive-data-sets' # write your path\n",
    "\n",
    "date = '20230621'\n",
    "fileName_list = [f'Tm9 proofreadings_{date}.xlsx',\n",
    "                 f'Tm16_neurons_outputs_count_L_Tm9_{date}.xlsx']\n",
    "\n",
    "filePath_list = []\n",
    "for fileName in fileName_list:\n",
    "    filePath_list.append(os.path.join(dataPath,fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dab603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose column information to compare and to transfer\n",
    "columns_to_compare = ['postsynaptic_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165b5f6",
   "metadata": {},
   "source": [
    "### Loading the distinct data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c44e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distinct dataframes will be stored in a dictionary\n",
    "\n",
    "data_frames = dict()\n",
    "\n",
    "for i in range(1, len(filePath_list)+1):\n",
    "    data_frames['df_%02d' % i] = pd.read_excel(filePath_list[i-1])\n",
    "    #Dropping the fisrt row ('asdf' was added as a walk-around to set that column values as type str)\n",
    "    if data_frames['df_%02d' % i][\"seg_id\"][0] == 'asdf': \n",
    "        data_frames['df_%02d' % i] = data_frames['df_%02d' % i].iloc[1: , :]\n",
    "        data_frames['df_%02d' % i].reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07216255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming some columns different to match the two dataframes\n",
    "for df_name in data_frames.keys():\n",
    "    if 'postsynaptic_ID' not in data_frames[df_name].columns:\n",
    "        data_frames[df_name]['postsynaptic_ID'] = data_frames[df_name]['seg_id']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8814f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose column information to compare and to transfer\n",
    "columns_to_compare = ['postsynaptic_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32549770",
   "metadata": {},
   "source": [
    "### Updating column information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8201ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distinct columns to update and the updated versions of them will be stored dictionaries\n",
    "columns_to_update = dict()\n",
    "for df_name in data_frames.keys():\n",
    "    curr_df = data_frames[df_name]\n",
    "    for column_name in columns_to_compare:\n",
    "        columns_to_update[f'{df_name}_{column_name}'] = curr_df[column_name].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the 'INPUTS PROOFREAD' or NaN labelled row of the lists for a well-known marker id\n",
    "\n",
    "marker_id = '720575940628553731' # VM1 ORN\n",
    "marker_id_update_df = flywire.update_ids(marker_id, stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "marker_id_updated = marker_id_update_df[\"new_id\"][0]\n",
    "for key,value in columns_to_update.items():\n",
    "    for i, id in enumerate(value):\n",
    "        if id == 'INPUTS PROOFREAD':\n",
    "            value[i] = marker_id_updated # Replacement by the marker\n",
    "        elif id == float('nan'):\n",
    "            value[i] = marker_id_updated # Replacement by the marker\n",
    "        elif math.isnan(float(id)):\n",
    "            value[i] = marker_id_updated # Replacement by the marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234cdadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the different columns. Information is stored in a dictionary\n",
    "updated_columns = dict()\n",
    "updated_columns_confidence = dict()\n",
    "for key, value in columns_to_update.items():\n",
    "    temp_segmentIDs_df = flywire.update_ids(value.tolist(), stop_layer=2, supervoxels=None, timestamp=None, dataset='production', progress=True)\n",
    "    updated_value = temp_segmentIDs_df[\"new_id\"]\n",
    "    confidence_of_update = temp_segmentIDs_df[\"confidence\"]\n",
    "    updated_columns[key] = updated_value\n",
    "    updated_columns_confidence[key] = confidence_of_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338481f",
   "metadata": {},
   "source": [
    "### Updating dataframe information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring the initial INPUTS PROOFREAD' marker\n",
    "for key, series in updated_columns.items():\n",
    "    updated_columns[key] = series.replace(to_replace = int(marker_id), value = 'INPUTS PROOFREAD')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e9d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the different dataframes inplace\n",
    "for df_name, df_values in data_frames.items():\n",
    "    for column_name in columns_to_compare:\n",
    "        data_frames[df_name][f'Updated_{column_name}'] =  updated_columns[f'{df_name}_{column_name}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c059772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following ids have been updated\n",
    "query_name = 'df_01'\n",
    "diff_df = data_frames[query_name].astype(str).loc[data_frames[query_name].astype(str)['Updated_postsynaptic_ID'] != data_frames[query_name].astype(str)['postsynaptic_ID']]\n",
    "print('Previous:')\n",
    "print(diff_df['postsynaptic_ID'].unique())\n",
    "print('Updated:')\n",
    "print(diff_df['Updated_postsynaptic_ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301000ce",
   "metadata": {},
   "source": [
    "### Transfering data from a source data frame into another\n",
    "#### Defining a function that performs the copy-paste operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataframe_single_column(source_df, target_df, reference_column):\n",
    "    # Create a dictionary mapping from the reference column to the source DataFrame\n",
    "    reference_dict = source_df.groupby(reference_column).first().reset_index().to_dict(orient='records')\n",
    "    reference_dict = {row[reference_column]: row for row in reference_dict}\n",
    "\n",
    "    # Update the target DataFrame based on the reference column\n",
    "    for i, row in target_df.iterrows():\n",
    "        ref = row[reference_column]\n",
    "        if ref in reference_dict:\n",
    "            source_row = reference_dict[ref]\n",
    "            target_df.loc[i] = source_row\n",
    "\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49de94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function inputs\n",
    "source_cols = ['XYZ-ME','XYZ-LO','optic_lobe_id', 'column_id','detached_lamina (Y/N)','healthy_L3 (Y/N)','postsynaptic_ID','Updated_postsynaptic_ID']\n",
    "target_cols = ['XYZ-ME','XYZ-LO','optic_lobe_id', 'column_id', 'detached_lamina (Y/N)','healthy_L3 (Y/N)','postsynaptic_ID','Updated_postsynaptic_ID']\n",
    "reference_column = 'postsynaptic_ID'\n",
    "\n",
    "# Selecting dataframes and resetting index\n",
    "source_df = data_frames['df_01'][source_cols].copy()\n",
    "source_df.reset_index(inplace = True, drop = True)\n",
    "target_df = data_frames['df_02'][target_cols].copy()\n",
    "target_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "source_df = source_df.astype(str)\n",
    "target_df = target_df.astype(str)\n",
    "\n",
    "# Running the function and compleating the dataset\n",
    "result_df = update_dataframe_single_column(source_df, target_df,reference_column)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8294d399",
   "metadata": {},
   "source": [
    "### Saving back to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1fddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating string for the date\n",
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "date_str = x.strftime(\"%d\") + x.strftime(\"%b\") + x.strftime(\"%Y\")\n",
    "\n",
    "# Writting in an existing excel file\n",
    "from openpyxl import load_workbook\n",
    "book = load_workbook(filePath_list[1])\n",
    "writer = pd.ExcelWriter(filePath_list[1], engine = 'openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "result_df = result_df.astype(str)\n",
    "result_df.to_excel(writer, sheet_name='Updated_table_'+date_str) #sorted_df\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f570791",
   "metadata": {},
   "source": [
    "## D) Combining information between tables for neuron authorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ebf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the first data frame\n",
    "\n",
    "# Choose path and file\n",
    "PC_disc = 'D'\n",
    "#dataPath = f'{PC_disc}:\\Connectomics-Data\\FlyWire\\Excels\\drive-data-sets\\submission_nature'\n",
    "dataPath = f'{PC_disc}:\\FlyWire-Data\\FlyWire-Authorship'\n",
    "date = '20240115'\n",
    "fileName = f'Segment IDs in publication_{date}.xlsx'\n",
    "\n",
    "filePath = os.path.join(dataPath,fileName)\n",
    "\n",
    "#Loading file as DataFrame\n",
    "df = pd.read_excel(filePath)\n",
    "\n",
    "\n",
    "#Dropping the fisrt row ('asdf' was added as a walk-around to set that column values as type str)\n",
    "if df[\"seg_id\"][0] == 'asdf': \n",
    "    df = df.iloc[1: , :]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "#Dropping dupllicates\n",
    "segment_publication_df = df.drop_duplicates(subset=[\"seg_id\"], keep='first')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df428491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the other dataframe\n",
    "\n",
    "# Choose path and file\n",
    "PC_disc = 'D'\n",
    "#dataPath = f'{PC_disc}:\\Connectomics-Data\\FlyWire\\Excels\\drive-data-sets\\submission_nature'\n",
    "dataPath = f'{PC_disc}:\\FlyWire-Data\\FlyWire-Authorship'\n",
    "date = '20240115'\n",
    "fileName = f'Multi-neuron-changelog-{date}.xlsx'\n",
    "filePath = os.path.join(dataPath,fileName)\n",
    "\n",
    "#Loading file as DataFrame\n",
    "df = pd.read_excel(filePath)\n",
    "\n",
    "\n",
    "#Dropping the fisrt row ('asdf' was added as a walk-around to set that column values as type str)\n",
    "if df[\"segment_ID\"][0] == 'asdf': \n",
    "    df = df.iloc[1: , :]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "change_log_df = df.copy()\n",
    "#change_log_df['segment_ID'] = change_log_df['segment_ID'].str.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ea641",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_publication_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tte ID column from the fisrt table to the second\n",
    "\n",
    "# Merge the data frames based on the common column \"Updated_seg_ids\"\n",
    "change_log_final = change_log_df.copy()\n",
    "merged_df = pd.merge(change_log_final, segment_publication_df, left_on='segment_ID', right_on='seg_id', how='left')\n",
    "\n",
    "# Add a new column \"neuron type\" to change_log_df using information from the \"symbol\" column\n",
    "change_log_final['neuron type'] = merged_df['symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c417d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_log_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7871287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving in a new file\n",
    "\n",
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "date_str = x.strftime(\"%d\") + x.strftime(\"%b\") + x.strftime(\"%Y\")\n",
    "file_name = f'change_log_final_{date_str}.xlsx'\n",
    "savePath = os.path.join(dataPath, file_name)\n",
    "change_log_final.to_excel(savePath, sheet_name='User-Lab summary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
